{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "008bd8f2-2793-4c28-afa3-faeceeb9e583",
   "metadata": {},
   "source": [
    "# Initialiser la Session Spark et Lire les Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "934d3aa7-d50c-4b2f-b9bd-e44a56e608b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m row_number, split, month, year, dayofweek, hour, col, \u001b[38;5;28msum\u001b[39m \u001b[38;5;28;01mas\u001b[39;00m _sum, avg \u001b[38;5;28;01mas\u001b[39;00m _avg, count \u001b[38;5;28;01mas\u001b[39;00m _count, \u001b[38;5;28mmax\u001b[39m \u001b[38;5;28;01mas\u001b[39;00m _max, \u001b[38;5;28mround\u001b[39m \u001b[38;5;28;01mas\u001b[39;00m _round, when, coalesce, datediff, current_date\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwindow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Window\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import row_number, split, month, year, dayofweek, hour, col, sum as _sum, avg as _avg, count as _count, max as _max, round as _round, when, coalesce, datediff, current_date\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Créer une session Spark avec des configurations optimisées\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"E-commerce Amazing Analysis\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
    "    .config(\"spark.driver.cores\", \"2\") \\\n",
    "    .config(\"spark.executor.cores\", \"2\") \\\n",
    "    .config(\"spark.memory.fraction\", \"0.8\") \\\n",
    "    .config(\"spark.memory.storageFraction\", \"0.2\") \\\n",
    "    .config(\"spark.memory.offHeap.enabled\", True) \\\n",
    "    .config(\"spark.memory.offHeap.size\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Définir le chemin du fichier Parquet\n",
    "output_path = \"/home/jovyan/work/filtered_df_output.parquet\"\n",
    "\n",
    "# Lire le fichier Parquet\n",
    "filtered_df = spark.read.parquet(output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afae07a6-be96-431e-af97-d75cb3236e4a",
   "metadata": {},
   "source": [
    "# Prétraitement des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f90a8bf-3dcd-4d85-9cb8-a19cbc80d979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Ajouter les colonnes 'month' et 'year'\n",
    "filtered_df = filtered_df.withColumn(\"month\", month(col(\"event_time\"))) \\\n",
    "                         .withColumn(\"year\", year(col(\"event_time\")))\n",
    "\n",
    "# Filtrer les événements d'achat\n",
    "purchase_df = filtered_df.filter(col(\"event_type\") == \"purchase\")\n",
    "\n",
    "# Extraire les paires uniques category_id et category_code\n",
    "category_mapping_df = purchase_df.select(\"category_id\", \"category_code\").distinct()\n",
    "\n",
    "# Sauvegarder ce mapping dans un fichier Parquet pour une utilisation ultérieure\n",
    "mapping_output_path = \"/home/jovyan/work/category_mapping.parquet\"\n",
    "category_mapping_df.write.mode(\"overwrite\").parquet(mapping_output_path)\n",
    "\n",
    "# Charger le mapping depuis le fichier Parquet\n",
    "category_mapping_df = spark.read.parquet(mapping_output_path)\n",
    "\n",
    "# Renommer la colonne 'category_code' dans le DataFrame de mapping pour éviter l'ambiguïté\n",
    "category_mapping_df = category_mapping_df.withColumnRenamed(\"category_code\", \"mapped_category_code\")\n",
    "\n",
    "# Joindre purchase_df avec category_mapping_df pour ajouter la colonne 'mapped_category_code'\n",
    "purchase_df_with_mapping = purchase_df.join(category_mapping_df, on=\"category_id\", how=\"left\")\n",
    "\n",
    "# Remplacer les valeurs NULL dans 'category_code' par les valeurs correspondantes de la jointure\n",
    "purchase_df = purchase_df_with_mapping.withColumn(\n",
    "    \"category_code\",\n",
    "    coalesce(purchase_df_with_mapping[\"category_code\"], purchase_df_with_mapping[\"mapped_category_code\"])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d44072-3d9f-4f6d-946b-a24446c3f669",
   "metadata": {},
   "source": [
    "# Calculer les Variables Quantitatives et Qualitatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7232db67",
   "metadata": {},
   "source": [
    "## Créer des variables qualitatives à partir de la colonne 'event_time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6d441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df.withColumn(\"event_day_of_week\", dayofweek(col(\"event_time\"))) \\\n",
    "                         .withColumn(\"event_hour\", hour(col(\"event_time\"))) \\\n",
    "                         .withColumn(\"event_weekend\", when(col(\"event_day_of_week\").isin([1, 7]), \"weekend\").otherwise(\"weekday\")) \\\n",
    "                         .withColumn(\"price_category\", when(col(\"price\") < 50, \"low\") \\\n",
    "                                                        .when((col(\"price\") >= 50) & (col(\"price\") < 200), \"medium\") \\\n",
    "                                                        .otherwise(\"high\")) \\\n",
    "                         .withColumn(\"time_of_day\", when(col(\"event_hour\").between(0, 6), \"night\") \\\n",
    "                                                    .when(col(\"event_hour\").between(7, 12), \"morning\") \\\n",
    "                                                    .when(col(\"event_hour\").between(13, 18), \"afternoon\") \\\n",
    "                                                    .otherwise(\"evening\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46819567",
   "metadata": {},
   "source": [
    "### 1. Nombre total de vues par utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f99900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_views = filtered_df.filter(col(\"event_type\") == \"view\") \\\n",
    "                             .groupBy(\"user_id\") \\\n",
    "                             .agg(_count(\"event_type\").alias(\"number_of_views\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f53be7",
   "metadata": {},
   "source": [
    "### 2. Nombre total de produits ajoutés au panier par utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebc447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_carts = filtered_df.filter(col(\"event_type\") == \"cart\") \\\n",
    "                             .groupBy(\"user_id\") \\\n",
    "                             .agg(_count(\"event_type\").alias(\"number_of_carts\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31783a71",
   "metadata": {},
   "source": [
    "\n",
    "### 3. Nombre total d'achats précédents par utilisateur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928ec7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_purchases = filtered_df.filter(col(\"event_type\") == \"purchase\") \\\n",
    "                                .groupBy(\"user_id\") \\\n",
    "                                .agg(_count(\"event_type\").alias(\"user_previous_purchases\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e3f248",
   "metadata": {},
   "source": [
    "### 4. Valeur moyenne des achats précédents par utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f771c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_purchase_value = filtered_df.filter(col(\"event_type\") == \"purchase\") \\\n",
    "                                    .groupBy(\"user_id\") \\\n",
    "                                    .agg(_round(_avg(\"price\"), 2).alias(\"user_average_purchase_value\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f2db1a",
   "metadata": {},
   "source": [
    "### 5. Temps écoulé depuis le dernier achat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17894f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "last_purchase_date = filtered_df.filter(col(\"event_type\") == \"purchase\") \\\n",
    "                                .groupBy(\"user_id\") \\\n",
    "                                .agg(_max(\"event_time\").alias(\"last_purchase_date\"))\n",
    "days_since_last_purchase = last_purchase_date.withColumn(\"days_since_last_purchase\", \n",
    "                                                         datediff(current_date(), col(\"last_purchase_date\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cca2b5",
   "metadata": {},
   "source": [
    "### 6. Nombre de produits ajoutés au panier mais non achetés (abandons de panier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e73c402",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cart_abandonments = filtered_df.filter(col(\"event_type\") == \"cart\") \\\n",
    "                               .groupBy(\"user_id\", \"product_id\") \\\n",
    "                               .agg(_count(\"event_type\").alias(\"cart_count\")) \\\n",
    "                               .join(purchase_df.groupBy(\"user_id\", \"product_id\").agg(_count(\"event_type\").alias(\"purchase_count\")),\n",
    "                                     on=[\"user_id\", \"product_id\"], how=\"left\") \\\n",
    "                               .withColumn(\"purchase_count\", col(\"purchase_count\").cast(\"int\")) \\\n",
    "                               .na.fill(0) \\\n",
    "                               .filter(col(\"purchase_count\") == 0) \\\n",
    "                               .groupBy(\"user_id\") \\\n",
    "                               .agg(_count(\"product_id\").alias(\"cart_abandonments\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d5faf1",
   "metadata": {},
   "source": [
    "### 7. Valeur totale des achats par utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1f2ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_purchase_value = filtered_df.filter(col(\"event_type\") == \"purchase\") \\\n",
    "                                  .groupBy(\"user_id\") \\\n",
    "                                  .agg(_round(_sum(\"price\"), 2).alias(\"total_purchase_value\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37db16ec",
   "metadata": {},
   "source": [
    "\n",
    "### 8. Nombre total de sessions par utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43cc4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_sessions = filtered_df.groupBy(\"user_id\") \\\n",
    "                                .agg(_count(\"user_session\").alias(\"number_of_sessions\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b1f90b",
   "metadata": {},
   "source": [
    "### 9. Calculer la valeur moyenne des achats pour déterminer le segment utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5725b66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_purchase_value = average_purchase_value.withColumn(\"user_segment\", when(col(\"user_average_purchase_value\") >= 100, \"high spender\").otherwise(\"regular buyer\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e850caae",
   "metadata": {},
   "source": [
    "### 10. Identifier la catégorie de produit préférée de l'utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5934bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preferred_category = filtered_df.filter(col(\"event_type\") == \"purchase\") \\\n",
    "                                .groupBy(\"user_id\", \"category_code\") \\\n",
    "                                .agg(_count(\"category_code\").alias(\"category_count\"))\n",
    "\n",
    "window_spec = Window.partitionBy(\"user_id\").orderBy(col(\"category_count\").desc())\n",
    "preferred_category = preferred_category.withColumn(\"rank\", row_number().over(window_spec)) \\\n",
    "                                       .filter(col(\"rank\") == 1) \\\n",
    "                                       .select(\"user_id\", \"category_code\") \\\n",
    "                                       .withColumnRenamed(\"category_code\", \"preferred_category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959492d2",
   "metadata": {},
   "source": [
    "### 11. Indicateur de fidélité à une marque spécifique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d28a4e5a-e427-4566-a775-e36bb06cc031",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_loyalty = filtered_df.filter(col(\"event_type\") == \"purchase\") \\\n",
    "                           .groupBy(\"user_id\", \"brand\") \\\n",
    "                           .agg(_count(\"brand\").alias(\"brand_count\"))\n",
    "\n",
    "window_spec = Window.partitionBy(\"user_id\").orderBy(col(\"brand_count\").desc())\n",
    "brand_loyalty = brand_loyalty.withColumn(\"rank\", row_number().over(window_spec)) \\\n",
    "                             .filter(col(\"rank\") == 1) \\\n",
    "                             .select(\"user_id\", \"brand\") \\\n",
    "                             .withColumnRenamed(\"brand\", \"preferred_brand\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0844632a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "158ca384-420f-47fe-bb9d-8f4a96826304",
   "metadata": {},
   "source": [
    "# Joindre les Variables Quantitatives et Qualitatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1637b062",
   "metadata": {},
   "source": [
    "## Joindre les DataFrames pour créer le DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7bf923",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = number_of_views.join(number_of_carts, \"user_id\", \"left\") \\\n",
    "                          .join(previous_purchases, \"user_id\", \"left\") \\\n",
    "                          .join(average_purchase_value.select(\"user_id\", \"user_average_purchase_value\", \"user_segment\"), \"user_id\", \"left\") \\\n",
    "                          .join(days_since_last_purchase, \"user_id\", \"left\") \\\n",
    "                          .join(cart_abandonments, \"user_id\", \"left\") \\\n",
    "                          .join(total_purchase_value, \"user_id\", \"left\") \\\n",
    "                          .join(number_of_sessions, \"user_id\", \"left\") \\\n",
    "                          .join(preferred_category, \"user_id\", \"left\") \\\n",
    "                          .join(brand_loyalty, \"user_id\", \"left\") \\\n",
    "                          .distinct()  # Suppression des duplicatas si nécessaire\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb74511b",
   "metadata": {},
   "source": [
    "## Remplacer les valeurs NULL par des valeurs par défaut si nécessaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2541f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.fillna({\n",
    "    \"number_of_views\": 0,\n",
    "    \"number_of_carts\": 0,\n",
    "    \"user_previous_purchases\": 0,\n",
    "    \"user_average_purchase_value\": 0.0,\n",
    "    \"days_since_last_purchase\": 9999,  # Utiliser une valeur par défaut pour indiquer une absence de précédent achat\n",
    "    \"cart_abandonments\": 0,\n",
    "    \"total_purchase_value\": 0.0,\n",
    "    \"number_of_sessions\": 0,\n",
    "    \"preferred_category\": \"unknown\",\n",
    "    \"preferred_brand\": \"unknown\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a64ceb45-fff3-4a81-96ee-77fa66f693eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les noms des colonnes du DataFrame final sont :\n",
      "user_id\n",
      "number_of_views\n",
      "number_of_carts\n",
      "user_previous_purchases\n",
      "user_average_purchase_value\n",
      "user_segment\n",
      "last_purchase_date\n",
      "days_since_last_purchase\n",
      "cart_abandonments\n",
      "total_purchase_value\n",
      "number_of_sessions\n",
      "preferred_category\n",
      "preferred_brand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+---------------+-----------------------+---------------------------+-------------+-------------------+------------------------+-----------------+--------------------+------------------+--------------------+---------------+\n",
      "|  user_id|number_of_views|number_of_carts|user_previous_purchases|user_average_purchase_value| user_segment| last_purchase_date|days_since_last_purchase|cart_abandonments|total_purchase_value|number_of_sessions|  preferred_category|preferred_brand|\n",
      "+---------+---------------+---------------+-----------------------+---------------------------+-------------+-------------------+------------------------+-----------------+--------------------+------------------+--------------------+---------------+\n",
      "|346998191|            207|              2|                      1|                       96.5|regular buyer|2020-03-13 14:25:20|                    1564|                1|                96.5|               210|appliances.enviro...|          huter|\n",
      "|378879891|            267|             14|                      5|                      63.19|regular buyer|2020-02-26 14:30:41|                    1580|                2|              315.94|               286|furniture.kitchen...|       redragon|\n",
      "|401375501|            157|             14|                      5|                     131.62| high spender|2020-04-17 09:47:21|                    1529|                4|              658.11|               176|appliances.kitche...|        kitfort|\n",
      "|403461581|             30|              3|                      2|                      167.0| high spender|2019-12-26 10:19:26|                    1642|                1|              333.99|                35|appliances.enviro...|        samsung|\n",
      "|424827221|             78|              6|                      1|                     142.29| high spender|2019-11-28 08:32:52|                    1670|                3|              142.29|                85|electronics.smart...|         xiaomi|\n",
      "|430321211|            161|              8|                      1|                     617.52| high spender|2019-12-23 03:52:27|                    1645|                3|              617.52|               170|appliances.kitche...|          bosch|\n",
      "|436328701|            127|              3|                      1|                     561.15| high spender|2019-12-20 09:56:30|                    1648|                1|              561.15|               131|construction.tool...|          apple|\n",
      "|438263431|            331|              5|                      4|                     173.74| high spender|2020-04-19 18:41:51|                    1527|                1|              694.95|               340|       apparel.shoes|       aerocool|\n",
      "|440832551|            215|              7|                      1|                      15.42|regular buyer|2020-01-31 13:44:05|                    1606|                4|               15.42|               223|appliances.kitche...|       scarlett|\n",
      "|448659331|             13|              3|                      1|                       8.98|regular buyer|2019-11-26 06:48:43|                    1672|                2|                8.98|                17|electronics.telep...|          texet|\n",
      "+---------+---------------+---------------+-----------------------+---------------------------+-------------+-------------------+------------------------+-----------------+--------------------+------------------+--------------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Afficher les noms des colonnes pour vérifier les nouvelles variables\n",
    "# print(\"Les noms des colonnes du DataFrame final sont :\")\n",
    "# for column in final_df.columns:\n",
    "#     print(column)\n",
    "\n",
    "# Afficher un échantillon des données pour vérifier les nouvelles variables\n",
    "final_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a470d1-60d1-4781-940f-13bc5f68cb1c",
   "metadata": {},
   "source": [
    "# Sauvegarder le DataFrame final dans un fichier Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed66fb5-7477-4adb-9bad-99cc6783e264",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output_path = \"/home/jovyan/work/final_df_output.parquet\"\n",
    "final_df.write.mode(\"overwrite\").parquet(final_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867e6a38",
   "metadata": {},
   "source": [
    "## Arrêter la session Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397d6b7a-0e7f-430b-ae63-6d13f0088aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
