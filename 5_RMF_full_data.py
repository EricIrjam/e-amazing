# %% [markdown]
# # Introduction
# 
# Suite √† notre analyse pr√©c√©dente bas√©e sur le clustering K-means (3_ACP_K-means_Amazing), bien que certains groupes d'utilisateurs aient √©t√© identifi√©s, les r√©sultats obtenus ne se sont pas r√©v√©l√©s pleinement satisfaisants. Cette premi√®re approche, qui s'appuyait sur un sous-ensemble du jeu de donn√©es, filtr√© par les clients dont le `user_id` se terminait par 1, avait r√©v√©l√© des diff√©rences significatives entre certains clusters. Cependant, ces clusters ne parvenaient pas √† capturer de mani√®re optimale les subtilit√©s du comportement des utilisateurs, notamment en ce qui concerne leur engagement et leur contribution √† la performance globale.
# 
# Afin d'approfondir notre compr√©hension des utilisateurs et de d√©velopper des actions marketing plus cibl√©es, nous avons d√©cid√© d'appliquer une nouvelle approche sur l'int√©gralit√© du jeu de donn√©es. En prenant en compte l'ensemble des utilisateurs, la m√©thode de Segmentation RFM (R√©cence, Fr√©quence, Valeur Mon√©taire), largement reconnue pour son efficacit√© dans les strat√©gies de fid√©lisation et de gestion de la relation client, se pr√©sente comme une solution plus adapt√©e et particuli√®rement pertinente.
# 
# ### √âtapes pour appliquer la m√©thode RFM :
# 1. **R√©cence (Recency)** : Nombre de jours depuis la derni√®re interaction ou achat.
# 2. **Fr√©quence (Frequency)** : Nombre de fois qu'un utilisateur a interagi ou achet√©.
# 3. **Valeur Mon√©taire (Monetary Value)** : Montant total d√©pens√© par l'utilisateur.
# 
# ### Calcul des Scores RFM :
# 1. **R√©cence** : Utiliser la colonne `days_since_last_purchase`.
# 2. **Fr√©quence** : Utiliser les colonnes de fr√©quence des interactions (`number_of_sessions_2m`, `number_of_sessions_5m`, etc.).
# 3. **Valeur Mon√©taire** : Utiliser `total_purchase_value`.
# 
# 
# En cons√©quence, nous allons explorer cette m√©thode pour obtenir une segmentation plus pertinente et align√©e sur nos objectifs commerciaux.
# 

# %%
# Importation des biblioth√®ques n√©cessaires 

import pyarrow.parquet as pq
import pyarrow as pa
import pandas as pd

from sklearn.preprocessing import StandardScaler, label_binarize
from sklearn.cluster import KMeans, MiniBatchKMeans
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc
import matplotlib.pyplot as plt
import seaborn as sns
from mpl_toolkits.mplot3d import Axes3D
from sklearn.metrics import silhouette_score
from sklearn.tree import plot_tree



# %%
# # URL directe vers le fichier Parquet sur GitHub
# base_url = "https://github.com/EricIrjam/e-amazing/raw/main/data/user_stats_df_output.parquet/"


# %%
# # Fonction pour r√©cup√©rer et lire tous les fichiers .parquet dans le r√©pertoire
# def read_parquet_files(base_url):
#     # Les fichiers que nous devons r√©cup√©rer
#     file_names = [
#         f"part-0000{i}-9b319896-debc-49c4-b0a7-fbbd59863d51-c000.snappy.parquet" for i in range(5)
#     ]

#     # Lire et combiner tous les fichiers Parquet en un seul DataFrame
#     tables = []
#     for file_name in file_names:
#         file_url = urljoin(base_url, file_name)
#         response = requests.get(file_url)
#         response.raise_for_status()

#         # Lire le fichier Parquet
#         table = pq.read_table(io.BytesIO(response.content))
#         tables.append(table)

#     # Combiner toutes les tables en une seule
#     combined_table = pa.concat_tables(tables)
#     return combined_table.to_pandas()

# %%
df = pd.read_parquet('data/full_df_output.parquet')

# %%
df.shape

# %% [markdown]
# # Mise en ≈ìuvre de la segmentation RFM et √©valuation des clusters
# 

# %%
# Conserver uniquement les colonnes n√©cessaires dans le DataFrame
df_reduit = df[['days_since_last_purchase', 'number_of_sessions_7m', 'total_purchase_value']].copy()

# Calcul des scores RFM
df_reduit['R_Score'] = pd.qcut(df_reduit['days_since_last_purchase'], q=4, labels=[4, 3, 2, 1])
df_reduit['F_Score'] = pd.qcut(df_reduit['number_of_sessions_7m'], q=4, labels=[1, 2, 3, 4])
df_reduit['M_Score'] = pd.qcut(df_reduit['total_purchase_value'], q=4, labels=[1, 2, 3, 4])


# %%
# Pr√©paration des donn√©es pour le clustering
X = df_reduit[['R_Score', 'F_Score', 'M_Score']].astype(int)

# %% [markdown]
# # 3. √âchantillonnage pour le d√©veloppement et ajustement des hyperparam√®tres (utiliser seulement 10% des donn√©es pour commencer)

# %%

df_sampled = df_reduit.sample(frac=0.1, random_state=42)
X_sampled = df_sampled[['R_Score', 'F_Score', 'M_Score']].astype(int)

# %%

# 4. Application de MiniBatchKMeans sur l'√©chantillon pour ajuster les param√®tres
silhouette_scores = []
range_n_clusters = range(2, 12)  # Tester entre 3 et 17 clusters

# %%
for n_clusters in range_n_clusters:
    # Initialisation de MiniBatchKMeans avec des param√®tres ajust√©s
    kmeans = MiniBatchKMeans(
        n_clusters=n_clusters,       # Nombre de clusters
        random_state=42,             # Graine pour reproductibilit√©
        batch_size=500,              # Taille des mini-lots r√©duite
        max_iter=50,                 # R√©duire le nombre d'it√©rations pour optimiser le temps
        init='k-means++'             # Initialisation optimis√©e
    )
    
    # Ex√©cution du clustering sur l'√©chantillon
    cluster_labels = kmeans.fit_predict(X_sampled)
    
    # Calcul du score de silhouette pour √©valuer la qualit√© du clustering
    silhouette_avg = silhouette_score(X_sampled, cluster_labels)
    
    # Ajout du score dans la liste
    silhouette_scores.append(silhouette_avg)

# %% [markdown]
# # Visualisation de l'√©volution de l'indice de silhouette en fonction du nombre de clusters

# %%
# Graphique de l'√©volution de l'indice de silhouette
plt.figure(figsize=(10, 5))
plt.plot(range_n_clusters, silhouette_scores, marker='o')
plt.title("√âvolution de l'indice de silhouette par nombre de clusters")
plt.xlabel("Nombre de clusters")
plt.ylabel("Indice de silhouette")
plt.grid(True)
plt.show()

# %% [markdown]
# 
# 
# 1. **Indice de silhouette** :
#    - Un indice de silhouette proche de 1 indique que les clusters sont bien s√©par√©s et denses.
#    - Un indice proche de 0 signifie que les clusters se chevauchent ou ne sont pas clairement distincts.
#    - Des valeurs n√©gatives (bien qu'il n'y en ait pas ici) indiquent que des points sont probablement affect√©s au mauvais cluster.
# 
# 2. **Nombre de clusters optimal** :
#    Nous observons un pic de l'indice de silhouette autour de 7 clusters, ce qui nous fait penser que 7 clusters pourraient √™tre un bon choix pour une segmentation optimale selon cet indicateur. Cependant, Si nous souhaitons aller plus loin dans la granularit√© de l'analyse, tester avec 8 ou 9 clusters pourrait nous offrir une segmentation plus d√©taill√©e des clients, en prenant en compte des crit√®res comme les gammes de produits ou la fr√©quence des achats.
# 
# 

# %%
# Clustering avec le nombre optimal de clusters trouv√©
optimal_clusters = 7
kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)
df_reduit['cluster'] = kmeans.fit_predict(X)

# %% [markdown]
# # Visualisation 3D du clustering RFM avec le nombre optimal de clusters

# %%
# 8. Application de MiniBatchKMeans sur l'ensemble des donn√©es avec le nombre optimal de clusters
kmeans_optimal = MiniBatchKMeans(
    n_clusters=optimal_clusters, 
    random_state=42, 
    batch_size=1000,              # Taille des mini-batches ajust√©e
    max_iter=100,                 # Nombre d'it√©rations augment√© pour garantir la convergence sur toutes les donn√©es
    # Utiliser tous les c≈ìurs CPU
    init='k-means++'            # Initialisation optimis√©e
)

# %%


# Graphique 3D du clustering
fig = plt.figure(figsize=(12, 8))
ax = fig.add_subplot(111, projection='3d')

# Cr√©ation du nuage de points avec les valeurs R, F, M et les clusters
scatter = ax.scatter(
    df_reduit['R_Score'],  # R√©cence
    df_reduit['F_Score'],  # Fr√©quence
    df_reduit['M_Score'],  # Valeur mon√©taire
    c=df_reduit['cluster'],  # Couleurs selon les clusters
    cmap='viridis',  # Palette de couleurs
    s=50,  # Taille des points
    alpha=0.8  # Transparence des points
)

# Titres et labels
ax.set_title('Clustering RFM - Visualisation 3D', fontsize=16)
ax.set_xlabel('R√©cence (R)', fontsize=12)
ax.set_ylabel('Fr√©quence (F)', fontsize=12)
ax.set_zlabel('Valeur Mon√©taire (M)', fontsize=12)

# Ajouter la barre de couleurs pour montrer les clusters
plt.colorbar(scatter)

# Afficher le graphique
plt.show()


# %% [markdown]
# #  S√©paration des donn√©es et de la cible pour le mod√®le de classification 
# 

# %%
X = df_reduit[['R_Score', 'F_Score', 'M_Score']]  # Caract√©ristiques RFM
y = df_reduit['cluster']  # Cible : cluster attribu√©

# %%
# Division des donn√©es en ensembles d'entra√Ænement et de test
data_train, data_test, target_train, target_test = train_test_split(X, y, test_size=0.2, random_state=42)


# %% [markdown]
# # Cr√©ation et entra√Ænement du mod√®le Decision Tree

# %%

tree = DecisionTreeClassifier(max_depth=3, random_state=42)
tree.fit(data_train, target_train)

# %% [markdown]
# #  Pr√©diction sur l'ensemble de test 

# %%

predictions = tree.predict(data_test)

# %% [markdown]
# # √âvaluation du mod√®le (accuracy) 

# %%

accuracy = accuracy_score(target_test, predictions)
print(f"Accuracy: {accuracy:.2f}")

# %% [markdown]
# # Afficher le rapport de classification et la matrice de confusion
# 

# %%
print("\nClassification Report:")
print(classification_report(target_test, predictions))

print("\nConfusion Matrix:")
conf_matrix = confusion_matrix(target_test, predictions)
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.title('Matrice de Confusion')
plt.xlabel('Pr√©dictions')
plt.ylabel('V√©rit√©s')
plt.show()

# %% [markdown]
# 
# 
# √Ä partir de la matrice de confusion, nous pouvons tirer des conclusions importantes sur les performances de notre mod√®le de classification.
# 
# Tout d'abord, nous remarquons que pour la **classe 0**, le mod√®le a correctement pr√©dit **29081** instances, ce qui montre une excellente performance, sans erreurs de classification pour cette classe.
# 
# Pour la **classe 1**, bien que le mod√®le ait correctement pr√©dit **32906** instances, nous observons **4374 erreurs** o√π les instances de la classe 1 ont √©t√© mal class√©es comme appartenant √† la classe 6. Cela montre un chevauchement significatif entre ces deux classes, ce qui pourrait indiquer que ces classes partagent des caract√©ristiques similaires dans les donn√©es. Malgr√© cela, le mod√®le reste performant avec une forte exactitude pour cette classe.
# 
# La **classe 2** a √©galement √©t√© bien classifi√©e, avec **10269** pr√©dictions correctes et aucune confusion avec les autres classes, indiquant une pr√©cision et un rappel tr√®s √©lev√©s pour cette classe.
# 
# Pour la **classe 3**, le mod√®le a correctement pr√©dit **26243** instances, mais nous observons que **4197** instances de la classe 3 ont √©t√© mal class√©es comme appartenant √† la classe 1. Cela pourrait indiquer un probl√®me de diff√©renciation entre ces deux classes, et cela pourrait expliquer pourquoi la pr√©cision pour la classe 3 pourrait √™tre l√©g√®rement plus faible.
# 
# La **classe 4** a √©galement pos√© des probl√®mes, avec **2928** instances mal class√©es comme appartenant √† la classe 1, bien que **17454** instances aient √©t√© correctement class√©es. Il est donc n√©cessaire d'am√©liorer la distinction entre ces classes.
# 
# Les **classes 5 et 6** montrent √©galement des r√©sultats encourageants, avec **16497** pr√©dictions correctes pour la classe 5 et **25372** pour la classe 6, bien qu'il y ait encore quelques erreurs, notamment avec les chevauchements avec d'autres classes.
# 
# <div style="border: 1px solid #B0E0E6; padding: 10px; background-color: #E0FFFF;"> 
# 
# Globalement, avec une **accuracy de 0.93**, les performances du mod√®le sont solides. Cependant, des am√©liorations sont possibles, en particulier pour mieux distinguer la **classe 1** de la **classe 6**, ainsi que pour corriger les confusions entre les **classes 3** et **1**.
# 
# </div>
# 
# 

# %% [markdown]
# # Visualisation de l'arbre de d√©cision
# 

# %%
# Entra√Ænement de l'arbre de d√©cision (comme dans la partie pr√©c√©dente du code)
# Nommons l'arbre de d√©cision "clf" pour √©viter le conflit avec le module "tree"
clf = DecisionTreeClassifier(max_depth=3, random_state=42)
clf.fit(data_train, target_train)

# D√©finir les noms des features et des classes pour l'affichage de l'arbre
feature_names = ['R_Score', 'F_Score', 'M_Score']
class_names = [str(cls) for cls in clf.classes_]  # Utiliser l'objet "clf" qui a √©t√© form√©

# Visualisation de l'arbre de d√©cision avec une taille de figure ajust√©e
_, ax = plt.subplots(figsize=(20, 14), dpi=100)  # Augmentation de la taille et de la r√©solution de la figure
plot_tree(
    clf,  # Utilisation du mod√®le "clf" ici
    feature_names=feature_names,
    class_names=class_names,
    impurity=False,
    filled=True,
    ax=ax,
    fontsize=9, 
    proportion=True
)

plt.title('Arbre de D√©cision des Clusters RFM', fontsize=18)
plt.show()

# %% [markdown]
# 
# En regardant cet arbre de d√©cision, nous pouvons associer diff√©rents groupes de clients √† des animaux pour mieux visualiser leurs comportements en fonction de leurs scores RFM (R√©cence, Fr√©quence, Montant) et des 7 classes identifi√©es.
# 
# ### Classification des clients selon les animaux :
# 
# 1. **Classe 0** (Clients avec un **R_Score ‚â§ 2.5**, **F_Score ‚â§ 2.5** et **M_Score > 2.5**) :
#    - Ces clients sont comme des **lions ü¶Å**. Ils sont puissants et dominants, effectuant de gros achats tout en √©tant relativement r√©cents. Ce sont des clients √† haute valeur ajout√©e qu'il faut choyer pour maximiser leur fid√©lit√©. 
# 
# 2. **Classe 1** (Clients avec un **R_Score ‚â§ 2.5**, **F_Score > 2.5** et **M_Score ‚â§ 2.5**) :
#    - Ces clients sont comme des **ours üêª**. Ils reviennent r√©guli√®rement et effectuent des achats mod√©r√©s. Ils ne sont pas aussi dynamiques que les lions, mais leur fid√©lit√© en fait un groupe stable √† ne pas n√©gliger.
# 
# 3. **Classe 2** (Clients avec un **R_Score ‚â§ 2.5**, **F_Score ‚â§ 2.5** et **M_Score ‚â§ 1.5**) :
#    - Ces clients ressemblent √† des **√©cureuils üêøÔ∏è**. Ils effectuent de petits achats occasionnels et ne sont pas tr√®s actifs. Ils accumulent petit √† petit sans faire de grosses d√©penses. Il peut √™tre int√©ressant de les activer davantage pour accro√Ætre leur contribution.
# 
# 4. **Classe 3** (Clients avec un **R_Score > 2.5**, **F_Score ‚â§ 2.5** et **M_Score ‚â• 3.5**) :
#    - Ce groupe se compare √† des **renards ü¶ä**. Ils sont discrets, mais lorsqu'ils reviennent, ils effectuent des achats importants. Ce sont des clients strat√©giques qu‚Äôil faut cibler pour des campagnes occasionnelles visant √† les faire revenir et d√©penser.
# 
# 5. **Classe 4** (Clients avec un **R_Score > 2.5**, **F_Score > 2.5** et **M_Score ‚â§ 3.5**) :
#    - Ils peuvent √™tre vus comme des **castors ü¶´**. Ils sont actifs et r√©guliers dans leurs achats, mais leur contribution mon√©taire est moyenne. Leurs habitudes sont pr√©visibles, et ils constituent un groupe fiable pour des programmes de fid√©lisation √† long terme.
# 
# 6. **Classe 5** (Clients avec un **R_Score ‚â§ 2.5**, **F_Score ‚â§ 2.5** et **M_Score entre 1.5 et 2.5**) :
#    - Ces clients peuvent √™tre compar√©s √† des **chouettes ü¶â**. Discrets et relativement silencieux, ils ne reviennent pas souvent, mais leurs achats sont mod√©r√©s. Ce groupe pourrait n√©cessiter des campagnes de r√©engagement pour augmenter la fr√©quence de leurs achats.
# 
# 7. **Classe 6** (Clients avec un **R_Score ‚â§ 2.5**, **F_Score ‚â§ 2.5** et **M_Score ‚â§ 1.5**) :
#    - Ils sont comme des **tortues üê¢**. Ils avancent lentement, avec des achats tr√®s peu fr√©quents et de faible montant. Ces clients ont besoin d'efforts significatifs pour les r√©activer ou de strat√©gies sp√©cifiques pour augmenter leur engagement.
# 
# ---
# 
# <div style="border: 1px solid #B0E0E6; padding: 10px; background-color: #E0FFFF;"> 
# 
# En r√©sum√©, cet arbre de d√©cision met en lumi√®re une vari√©t√© de comportements clients qui peuvent √™tre associ√©s √† diff√©rents animaux : des **lions ü¶Å** pour les gros d√©pensiers r√©cents, aux **tortues üê¢** pour ceux qui sont moins actifs et d√©pensent peu. Cette segmentation peut aider √† personnaliser les strat√©gies marketing pour chaque groupe, avec un accent particulier sur la fid√©lisation des **lions** et des **ours**, tout en r√©activant les **tortues** et les **chouettes**.
# 
# </div>
# 

# %% [markdown]
# 

# %% [markdown]
# # Visualisation de la courbe ROC AUC

# %%

# Si multiclass, binarisation des classes
target_train_bin = label_binarize(target_train, classes=[0, 1, 2, 3, 4, 5, 6])
target_test_bin = label_binarize(target_test, classes=[0, 1, 2, 3, 4, 5, 6])
n_classes = target_train_bin.shape[1]

# Obtenir les probabilit√©s de pr√©diction
y_score = clf.predict_proba(data_test)

# Initialiser les variables pour la courbe ROC AUC
fpr = dict()
tpr = dict()
roc_auc = dict()

# Calculer la courbe ROC et AUC pour chaque classe
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(target_test_bin[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Tracer la courbe ROC pour chaque classe
plt.figure(figsize=(10, 8))
colors = ['aqua', 'darkorange', 'cornflowerblue', 'red', 'purple', 'green', 'blue']
for i in range(n_classes):
    plt.plot(fpr[i], tpr[i], color=colors[i],
             lw=2, label=f'Classe {i} (AUC = {roc_auc[i]:.2f})')

# Graphique de la courbe ROC
plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taux de Faux Positifs')
plt.ylabel('Taux de Vrais Positifs')
plt.title('Courbe ROC AUC multi-classe pour un arbre de d√©cision')
plt.legend(loc="lower right")
plt.show()


# %% [markdown]
# L‚Äôinterpr√©tation de cette courbe ROC AUC pour un arbre de d√©cision multi-classe repose sur les performances du mod√®le en termes de capacit√© √† s√©parer les diff√©rentes classes. Chaque courbe ROC trace le taux de vrais positifs (sensitivity) contre le taux de faux positifs (1-specificity), et l‚Äôaire sous la courbe (AUC) donne une id√©e globale des performances du mod√®le pour chaque classe.
# 
# ### Analyse des courbes ROC pour chaque classe :
# 
# 1. **Classe 0 **lions ü¶Å** (AUC = 1.00)** : 
#    - La courbe ROC pour la classe 0 montre un AUC parfait de 1.00, ce qui signifie que le mod√®le distingue parfaitement cette classe sans aucune erreur. Cela sugg√®re que le mod√®le classifie parfaitement les √©chantillons de cette classe.
#    
# 2. **Classe 1 ours üêª (AUC = 0.98)** :
#    - L‚ÄôAUC de 0.98 pour la classe 1 montre que le mod√®le est presque parfait pour distinguer cette classe des autres, avec une tr√®s l√©g√®re perte de performance. Le mod√®le fait tr√®s peu d'erreurs lors de la classification des √©chantillons de la classe 1, mais quelques faux positifs ou faux n√©gatifs subsistent.
#    
# 3. **Classe 2 √©cureuils üêøÔ∏è (AUC = 1.00)** :
#    - Tout comme la classe 0, la classe 2 a un AUC parfait de 1.00, indiquant que le mod√®le distingue parfaitement cette classe. Aucune erreur de classification n‚Äôest observ√©e pour cette classe.
#    
# 4. **Classe 3 renards ü¶ä (AUC = 1.00)** :
#    - L‚ÄôAUC de 1.00 pour la classe 3 est √©galement parfaite, indiquant que le mod√®le classe les √©chantillons de cette classe sans erreur. Le mod√®le a donc un excellent comportement pour cette classe.
#    
# 5. **Classe 4 castors ü¶´ (AUC = 1.00)** :
#    - Comme pour les classes pr√©c√©dentes avec un AUC de 1.00, cela indique que le mod√®le est capable de s√©parer parfaitement les √©chantillons de la classe 4. Pas de faux positifs ni de faux n√©gatifs.
#    
# 6. **Classe 5 chouettes ü¶â (AUC = 1.00)** :
#    - Un autre cas d‚ÄôAUC parfait. Le mod√®le se comporte parfaitement pour la classe 5, ce qui sugg√®re une classification sans erreur pour cette classe.
#    
# 7. **Classe 6 tortues üê¢(AUC = 0.98)** :
#    - Comme pour la classe 1, l‚ÄôAUC pour la classe 6 est tr√®s proche de la perfection √† 0.98. Cela indique une excellente s√©paration de cette classe, mais il reste quelques erreurs mineures o√π des √©chantillons de la classe 6 sont mal class√©s ou d‚Äôautres classes sont confondues avec la classe 6.
# 
# ### Interpr√©tation g√©n√©rale :
# - **AUC √©lev√© (proche de 1.00)** : Les courbes montrent que le mod√®le est excellent pour diff√©rencier les classes entre elles. Avec des AUC allant de 0.98 √† 1.00, cela montre que le mod√®le a une tr√®s bonne capacit√© discriminante.
# - **Classes avec AUC = 1.00** : Les classes 0, 2, 3, 4 et 5 sont parfaitement diff√©renci√©es par le mod√®le, ce qui signifie que le mod√®le n‚Äôa fait aucune erreur pour ces classes, que ce soit en faux positifs ou faux n√©gatifs.
# - **Classes avec AUC = 0.98** : Les classes 1 et 6 montrent une tr√®s l√©g√®re perte de performance (AUC = 0.98). Cela signifie qu‚Äôil y a quelques erreurs de classification, mais globalement, le mod√®le reste tr√®s performant pour ces classes.
# 
# ### Conclusion :
# Le mod√®le d'arbre de d√©cision utilis√© pour la classification des clients semble extr√™mement performant avec des **AUC tr√®s proches de 1.00** pour toutes les classes, sugg√©rant une excellente capacit√© √† classer correctement les √©chantillons. Pour les classes 1 et 6, de petites am√©liorations peuvent √™tre apport√©es, mais les erreurs sont tr√®s minimes.
# 
# En termes pratiques, cela signifie que le mod√®le est particuli√®rement adapt√© √† la segmentation des clients dans le contexte RFM (R√©cence, Fr√©quence, Montant), avec une capacit√© presque parfaite √† discriminer les diff√©rents types de comportements clients.

# %% [markdown]
# 


